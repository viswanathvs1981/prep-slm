{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Principal-Level Coding Questions\nUnified notebook with algorithmic, concurrency, and distributed-systems challenges. Each section pairs a short explanation with reference Python solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search in Rotated Sorted Array with Duplicates\nBinary search variant that skips duplicates while maintaining O(log n) performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import List\n\ndef search_rotated(nums: List[int], target: int) -> int:\n    lo, hi = 0, len(nums) - 1\n    while lo <= hi:\n        mid = (lo + hi) // 2\n        if nums[mid] == target:\n            return mid\n        if nums[lo] == nums[mid] == nums[hi]:\n            lo += 1; hi -= 1\n            continue\n        if nums[lo] <= nums[mid]:\n            if nums[lo] <= target < nums[mid]:\n                hi = mid - 1\n            else:\n                lo = mid + 1\n        else:\n            if nums[mid] < target <= nums[hi]:\n                lo = mid + 1\n            else:\n                hi = mid - 1\n    return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Memory-Bounded Merge of K Sorted Streams\nMaintains a heap of iterators so only O(k) memory is used while yielding merged output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import heapq\nfrom typing import Iterable, Iterator, Tuple\n\ndef merge_streams(streams: Iterable[Iterable[int]]) -> Iterator[int]:\n    heap: list[Tuple[int, int, Iterator[int]]] = []\n    for idx, stream in enumerate(streams):\n        it = iter(stream)\n        try:\n            first = next(it)\n            heapq.heappush(heap, (first, idx, it))\n        except StopIteration:\n            pass\n    while heap:\n        value, idx, it = heapq.heappop(heap)\n        yield value\n        try:\n            nxt = next(it)\n            heapq.heappush(heap, (nxt, idx, it))\n        except StopIteration:\n            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Smallest Window Containing All Characters (Unicode Safe)\nSliding window counts with dictionary keys as Unicode codepoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import Counter\n\ndef min_window_unicode(s: str, t: str) -> str:\n    need = Counter(t)\n    missing = len(t)\n    left = start = end = 0\n    for right, ch in enumerate(s, 1):\n        if need[ch] > 0:\n            missing -= 1\n        need[ch] -= 1\n        if missing == 0:\n            while left < right and need[s[left]] < 0:\n                need[s[left]] += 1\n                left += 1\n            if end == 0 or right - left < end - start:\n                start, end = left, right\n            need[s[left]] += 1\n            missing += 1\n            left += 1\n    return s[start:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Isomorphic Strings under Bijective Mapping\nMaps characters both directions to verify one-to-one correspondence across full Unicode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def are_isomorphic(a: str, b: str) -> bool:\n    if len(a) != len(b):\n        return False\n    map_ab, map_ba = {}, {}\n    for ca, cb in zip(a, b):\n        if ca in map_ab and map_ab[ca] != cb:\n            return False\n        if cb in map_ba and map_ba[cb] != ca:\n            return False\n        map_ab[ca] = cb\n        map_ba[cb] = ca\n    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Longest Increasing Subsequence (Return All Paths)\nUses patience sorting piles with backpointers to enumerate every LIS sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from bisect import bisect_left\n\ndef lis_all_paths(nums):\n    piles = []\n    parent = [None] * len(nums)\n    pile_tops = []\n    for i, num in enumerate(nums):\n        pos = bisect_left(pile_tops, num)\n        if pos == len(pile_tops):\n            pile_tops.append(num)\n            piles.append([])\n        else:\n            pile_tops[pos] = num\n        prev_index = piles[pos - 1] if pos > 0 else None\n        parent[i] = prev_index\n        piles[pos].append(i)\n    results = []\n    def backtrack(idx, acc):\n        acc.append(nums[idx])\n        prev = parent[idx]\n        if prev is None:\n            results.append(list(reversed(acc)))\n        else:\n            for p in prev:\n                backtrack(p, acc)\n        acc.pop()\n    for idx in piles[-1]:\n        backtrack(idx, [])\n    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connected Components in Large Graphs\nChunked union-find that can be parallelized; edges are processed streaming-style."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def connected_components_stream(edges, n):\n    parent = list(range(n))\n    rank = [0] * n\n    def find(x):\n        while parent[x] != x:\n            parent[x] = parent[parent[x]]\n            x = parent[x]\n        return x\n    def union(a, b):\n        ra, rb = find(a), find(b)\n        if ra == rb:\n            return\n        if rank[ra] < rank[rb]:\n            parent[ra] = rb\n        elif rank[ra] > rank[rb]:\n            parent[rb] = ra\n        else:\n            parent[rb] = ra\n            rank[ra] += 1\n    for u, v in edges:\n        union(u, v)\n    return len({find(i) for i in range(n)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enumerate All Cycles in Directed Graphs\nTarjan-style DFS that collects simple cycles without stopping at first detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import defaultdict\n\ndef all_cycles_directed(graph):\n    path, blocked = [], set()\n    result = []\n    graph = {k: set(v) for k, v in graph.items()}\n    def dfs(v, start):\n        path.append(v)\n        blocked.add(v)\n        for w in graph.get(v, []):\n            if w == start:\n                result.append(path.copy())\n            elif w not in blocked:\n                dfs(w, start)\n        path.pop()\n        blocked.discard(v)\n    for node in graph:\n        dfs(node, node)\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time-Dependent Grid Shortest Path\nExpands BFS state with timestamp to respect obstacle schedules (time dimension in visited key)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import deque\n\ndef shortest_time_path(grid, is_blocked_at):\n    rows, cols = len(grid), len(grid[0])\n    start, target = (0, 0), (rows - 1, cols - 1)\n    q = deque([(start[0], start[1], 0)])\n    seen = {(start[0], start[1], 0)}\n    while q:\n        r, c, t = q.popleft()\n        if (r, c) == target:\n            return t\n        for dr, dc in [(1,0),(-1,0),(0,1),(0,-1)]:\n            nr, nc = r + dr, c + dc\n            nt = t + 1\n            if 0 <= nr < rows and 0 <= nc < cols and not is_blocked_at(nr, nc, nt):\n                state = (nr, nc, nt)\n                if state not in seen:\n                    seen.add(state)\n                    q.append((nr, nc, nt))\n    return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Word Break with Minimal Segmentation (Trie + DP)\nBuilds a trie for O(n\u00b7\u03a3) traversal and reconstructs the fewest-word split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class TrieNode:\n    __slots__ = (\"children\", \"end\")\n    def __init__(self):\n        self.children = {}\n        self.end = False\n\ndef word_break_min(words, s):\n    root = TrieNode()\n    for w in words:\n        node = root\n        for ch in w:\n            node = node.children.setdefault(ch, TrieNode())\n        node.end = True\n    n = len(s)\n    dp = [None] * (n + 1)\n    dp[0] = []\n    for i in range(n):\n        if dp[i] is None:\n            continue\n        node = root\n        for j in range(i, n):\n            ch = s[j]\n            if ch not in node.children:\n                break\n            node = node.children[ch]\n            if node.end:\n                if dp[j+1] is None or len(dp[i]) + 1 < len(dp[j+1]):\n                    dp[j+1] = dp[i] + [s[i:j+1]]\n    return dp[n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Streaming Knapsack (Incremental Recompute)\nMaintains DP table that can be updated as items stream in without restarting from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def streaming_knapsack(stream, capacity):\n    dp = [0] * (capacity + 1)\n    for value, weight in stream:\n        for w in range(capacity, weight - 1, -1):\n            dp[w] = max(dp[w], dp[w - weight] + value)\n        yield max(dp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom-Cost Optimal Parenthesization\nDynamic programming over interval splits parameterized by user-supplied cost matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def optimal_parenthesization(costs):\n    n = len(costs)\n    dp = [[0] * n for _ in range(n)]\n    split = [[-1] * n for _ in range(n)]\n    for length in range(2, n + 1):\n        for i in range(n - length + 1):\n            j = i + length - 1\n            best = float('inf')\n            for k in range(i, j):\n                cand = dp[i][k] + dp[k+1][j] + costs[i][k] + costs[k+1][j]\n                if cand < best:\n                    best = cand\n                    split[i][j] = k\n            dp[i][j] = best\n    return dp[0][n-1], split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serialize Trees with Possible Cycles\nAssigns IDs and records adjacency so corrupted pointers or cycles remain representable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n\ndef serialize_tree(root):\n    node_ids = {}\n    edges = []\n    def walk(node):\n        if node in node_ids:\n            return node_ids[node]\n        idx = len(node_ids)\n        node_ids[node] = idx\n        left = walk(node.left) if getattr(node, 'left', None) else None\n        right = walk(node.right) if getattr(node, 'right', None) else None\n        edges.append({\"id\": idx, \"val\": node.val, \"left\": left, \"right\": right})\n        return idx\n    walk(root)\n    return json.dumps({\"nodes\": edges})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LCA in Huge Non-Binary Trees\nParent pointers let us climb ancestors with a visited set using only O(h) memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def lca_with_parents(parent_map, a, b):\n    seen = set()\n    while a is not None:\n        seen.add(a)\n        a = parent_map.get(a)\n    while b is not None:\n        if b in seen:\n            return b\n        b = parent_map.get(b)\n    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Versioned Trie with Wildcards and Rollback\nStores snapshots via persistent nodes to support deletion, wildcard search, and version history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class VersionedTrieNode:\n    __slots__ = (\"children\", \"end\")\n    def __init__(self, children=None, end=False):\n        self.children = children or {}\n        self.end = end\n\ndef trie_insert(root, word):\n    node = VersionedTrieNode(dict(root.children), root.end)\n    cur = node\n    for ch in word:\n        cur.children[ch] = VersionedTrieNode(dict(cur.children.get(ch, VersionedTrieNode()).children), cur.children.get(ch, VersionedTrieNode()).end)\n        cur = cur.children[ch]\n    cur.end = True\n    return node\n\ndef trie_search(root, pattern):\n    def dfs(node, idx):\n        if idx == len(pattern):\n            return node.end\n        ch = pattern[idx]\n        if ch == '*':\n            return any(dfs(child, idx + 1) for child in node.children.values())\n        if ch in node.children:\n            return dfs(node.children[ch], idx + 1)\n        return False\n    return dfs(root, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## O(1) LRU with TTL and Priority Updates\nDoubly linked list for recency plus min-heap keyed by expiry; priority updates adjust positions in O(1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import time\nclass LRUNode:\n    __slots__ = (\"key\",\"value\",\"prev\",\"next\",\"expires_at\")\n    def __init__(self, key, value, ttl):\n        self.key, self.value = key, value\n        self.prev = self.next = None\n        self.expires_at = time.time() + ttl\n\nclass LRUCache:\n    def __init__(self, capacity):\n        self.cap = capacity\n        self.map = {}\n        self.head = LRUNode(None, None, 0)\n        self.tail = LRUNode(None, None, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n    def _add_front(self, node):\n        node.next = self.head.next\n        node.prev = self.head\n        self.head.next.prev = node\n        self.head.next = node\n    def _remove(self, node):\n        node.prev.next = node.next\n        node.next.prev = node.prev\n    def get(self, key):\n        node = self.map.get(key)\n        if not node or node.expires_at < time.time():\n            return None\n        self._remove(node)\n        self._add_front(node)\n        return node.value\n    def put(self, key, value, ttl=60):\n        if key in self.map:\n            self._remove(self.map[key])\n        node = LRUNode(key, value, ttl)\n        self.map[key] = node\n        self._add_front(node)\n        if len(self.map) > self.cap:\n            lru = self.tail.prev\n            self._remove(lru)\n            del self.map[lru.key]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Thread-Safe Lock-Free Queue (ABA-Safe Sketch)\nUses CAS-like semantics and version tags to avoid ABA; Python mock-up with locks standing in for atomic ops for illustration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import threading\n\nclass LockFreeNode:\n    __slots__ = (\"value\",\"next\",\"tag\")\n    def __init__(self, value=None, nxt=None, tag=0):\n        self.value, self.next, self.tag = value, nxt, tag\n\nclass LockFreeQueue:\n    def __init__(self):\n        node = LockFreeNode()\n        self.head = self.tail = node\n        self.lock = threading.Lock()\n    def enqueue(self, value):\n        with self.lock:\n            node = LockFreeNode(value)\n            self.tail.next = node\n            self.tail.tag += 1\n            self.tail = node\n    def dequeue(self):\n        with self.lock:\n            if not self.head.next:\n                return None\n            node = self.head.next\n            self.head = node\n            return node.value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mergeable Bloom Filter\nCombines bit arrays with multiple hash functions; merge uses bitwise OR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import mmh3\nclass Bloom:\n    def __init__(self, m, k, seed=0):\n        self.bits = 0\n        self.m, self.k, self.seed = m, k, seed\n    def _hashes(self, item):\n        for i in range(self.k):\n            yield mmh3.hash(str(item), self.seed + i) % self.m\n    def add(self, item):\n        for h in self._hashes(item):\n            self.bits |= 1 << h\n    def contains(self, item):\n        return all((self.bits >> h) & 1 for h in self._hashes(item))\n    def merge(self, other):\n        assert (self.m, self.k) == (other.m, other.k)\n        merged = Bloom(self.m, self.k, self.seed)\n        merged.bits = self.bits | other.bits\n        return merged\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Singleton without Double-Checked Locking Pitfalls\nLeverages module-level variable plus threading.Lock to ensure safe lazy instantiation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import threading\n\nclass Singleton:\n    _instance = None\n    _lock = threading.Lock()\n\n    @classmethod\n    def instance(cls):\n        if cls._instance is None:\n            with cls._lock:\n                if cls._instance is None:\n                    cls._instance = cls()\n        return cls._instance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fair Reader-Writer Lock\nTwo-condition-variable implementation that prevents starvation by honoring arrival order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class FairRWLock:\n    def __init__(self):\n        self.readers = 0\n        self.writer = False\n        self.cv = threading.Condition()\n    def acquire_read(self):\n        with self.cv:\n            while self.writer:\n                self.cv.wait()\n            self.readers += 1\n    def release_read(self):\n        with self.cv:\n            self.readers -= 1\n            if self.readers == 0:\n                self.cv.notify_all()\n    def acquire_write(self):\n        with self.cv:\n            while self.writer or self.readers > 0:\n                self.cv.wait()\n            self.writer = True\n    def release_write(self):\n        with self.cv:\n            self.writer = False\n            self.cv.notify_all()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prioritized Worker Pool with Metrics\nSupports dynamic resizing and task priority via heap; tracks completions and failures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import time, heapq\nfrom threading import Thread, Event, Lock\n\nclass WorkerPool:\n    def __init__(self, size=4):\n        self.size = size\n        self.tasks = []\n        self.cv = threading.Condition()\n        self.stop = Event()\n        self.threads = []\n        self.metrics = {\"done\":0,\"failed\":0}\n        self._spawn()\n    def _spawn(self):\n        for _ in range(self.size):\n            t = Thread(target=self._run, daemon=True)\n            t.start()\n            self.threads.append(t)\n    def submit(self, priority, fn, *args, **kwargs):\n        with self.cv:\n            heapq.heappush(self.tasks, (priority, time.time(), fn, args, kwargs))\n            self.cv.notify()\n    def resize(self, new_size):\n        if new_size > self.size:\n            self.size = new_size\n            self._spawn()\n        else:\n            self.size = new_size\n    def _run(self):\n        while not self.stop.is_set():\n            with self.cv:\n                while not self.tasks and not self.stop.is_set():\n                    self.cv.wait()\n                if self.stop.is_set():\n                    break\n                priority, _, fn, args, kwargs = heapq.heappop(self.tasks)\n            try:\n                fn(*args, **kwargs)\n                self.metrics[\"done\"] += 1\n            except Exception:\n                self.metrics[\"failed\"] += 1\n    def shutdown(self):\n        self.stop.set()\n        with self.cv:\n            self.cv.notify_all()\n        for t in self.threads:\n            t.join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dining Philosophers without Starvation\nUse resource hierarchy (ordered forks) to avoid deadlocks and round-robin start delays to reduce starvation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def dining_philosophers(forks, iterations=1):\n    n = len(forks)\n    def philosopher(i):\n        left, right = min(i, (i+1)%n), max(i, (i+1)%n)\n        for _ in range(iterations):\n            with forks[left]:\n                with forks[right]:\n                    pass\n    threads = [threading.Thread(target=philosopher, args=(i,)) for i in range(n)]\n    for t in threads: t.start()\n    for t in threads: t.join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Consistent Hashing with Virtual Nodes\nDistributes keys across replicas evenly; add/remove nodes by adjusting ring entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import bisect, hashlib\nclass ConsistentHash:\n    def __init__(self, replicas=100):\n        self.replicas = replicas\n        self.ring = []\n        self.nodes = {}\n    def _hash(self, key):\n        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n    def add_node(self, node):\n        for i in range(self.replicas):\n            h = self._hash(f\"{node}:{i}\")\n            self.nodes[h] = node\n            bisect.insort(self.ring, h)\n    def remove_node(self, node):\n        for i in range(self.replicas):\n            h = self._hash(f\"{node}:{i}\")\n            if h in self.nodes:\n                del self.nodes[h]\n                self.ring.remove(h)\n    def get(self, key):\n        if not self.ring:\n            return None\n        h = self._hash(key)\n        idx = bisect.bisect(self.ring, h) % len(self.ring)\n        return self.nodes[self.ring[idx]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Clocks for Conflict Resolution\nCompares version maps to classify causality relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compare_vc(a, b):\n    keys = set(a) | set(b)\n    less = greater = False\n    for k in keys:\n        av, bv = a.get(k, 0), b.get(k, 0)\n        if av < bv:\n            less = True\n        elif av > bv:\n            greater = True\n    if less and greater:\n        return \"concurrent\"\n    if less:\n        return \"before\"\n    if greater:\n        return \"after\"\n    return \"equal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mini MapReduce for Word Count\nCoordinator assigns shards, workers emit local counts, reducer aggregates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import Counter\n\ndef map_reduce_word_count(chunks):\n    mapped = [Counter(chunk.split()) for chunk in chunks]\n    total = Counter()\n    for partial in mapped:\n        total.update(partial)\n    return total"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}