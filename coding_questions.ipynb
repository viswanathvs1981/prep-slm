{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Principal-Level Coding Questions\nUnified notebook with algorithmic, concurrency, and distributed-systems challenges. Each section pairs a short explanation with reference Python solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search in Rotated Sorted Array with Duplicates\nBinary search variant that skips duplicates while maintaining O(log n) performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from typing import List\n\ndef search_rotated(nums: List[int], target: int) -> int:\n    lo, hi = 0, len(nums) - 1\n    while lo <= hi:\n        mid = (lo + hi) // 2\n        if nums[mid] == target:\n            return mid\n        if nums[lo] == nums[mid] == nums[hi]:\n            lo += 1; hi -= 1\n            continue\n        if nums[lo] <= nums[mid]:\n            if nums[lo] <= target < nums[mid]:\n                hi = mid - 1\n            else:\n                lo = mid + 1\n        else:\n            if nums[mid] < target <= nums[hi]:\n                lo = mid + 1\n            else:\n                hi = mid - 1\n    return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Memory-Bounded Merge of K Sorted Streams\nMaintains a heap of iterators so only O(k) memory is used while yielding merged output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import heapq\nfrom typing import Iterable, Iterator, Tuple\n\ndef merge_streams(streams: Iterable[Iterable[int]]) -> Iterator[int]:\n    heap: list[Tuple[int, int, Iterator[int]]] = []\n    for idx, stream in enumerate(streams):\n        it = iter(stream)\n        try:\n            first = next(it)\n            heapq.heappush(heap, (first, idx, it))\n        except StopIteration:\n            pass\n    while heap:\n        value, idx, it = heapq.heappop(heap)\n        yield value\n        try:\n            nxt = next(it)\n            heapq.heappush(heap, (nxt, idx, it))\n        except StopIteration:\n            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Smallest Window Containing All Characters (Unicode Safe)\nSliding window counts with dictionary keys as Unicode codepoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import Counter\n\ndef min_window_unicode(s: str, t: str) -> str:\n    need = Counter(t)\n    missing = len(t)\n    left = start = end = 0\n    for right, ch in enumerate(s, 1):\n        if need[ch] > 0:\n            missing -= 1\n        need[ch] -= 1\n        if missing == 0:\n            while left < right and need[s[left]] < 0:\n                need[s[left]] += 1\n                left += 1\n            if end == 0 or right - left < end - start:\n                start, end = left, right\n            need[s[left]] += 1\n            missing += 1\n            left += 1\n    return s[start:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Isomorphic Strings under Bijective Mapping\nMaps characters both directions to verify one-to-one correspondence across full Unicode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def are_isomorphic(a: str, b: str) -> bool:\n    if len(a) != len(b):\n        return False\n    map_ab, map_ba = {}, {}\n    for ca, cb in zip(a, b):\n        if ca in map_ab and map_ab[ca] != cb:\n            return False\n        if cb in map_ba and map_ba[cb] != ca:\n            return False\n        map_ab[ca] = cb\n        map_ba[cb] = ca\n    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Longest Increasing Subsequence (Return All Paths)\nUses patience sorting piles with backpointers to enumerate every LIS sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from bisect import bisect_left\n\ndef lis_all_paths(nums):\n    piles = []\n    parent = [None] * len(nums)\n    pile_tops = []\n    for i, num in enumerate(nums):\n        pos = bisect_left(pile_tops, num)\n        if pos == len(pile_tops):\n            pile_tops.append(num)\n            piles.append([])\n        else:\n            pile_tops[pos] = num\n        prev_index = piles[pos - 1] if pos > 0 else None\n        parent[i] = prev_index\n        piles[pos].append(i)\n    results = []\n    def backtrack(idx, acc):\n        acc.append(nums[idx])\n        prev = parent[idx]\n        if prev is None:\n            results.append(list(reversed(acc)))\n        else:\n            for p in prev:\n                backtrack(p, acc)\n        acc.pop()\n    for idx in piles[-1]:\n        backtrack(idx, [])\n    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connected Components in Large Graphs\nChunked union-find that can be parallelized; edges are processed streaming-style."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def connected_components_stream(edges, n):\n    parent = list(range(n))\n    rank = [0] * n\n    def find(x):\n        while parent[x] != x:\n            parent[x] = parent[parent[x]]\n            x = parent[x]\n        return x\n    def union(a, b):\n        ra, rb = find(a), find(b)\n        if ra == rb:\n            return\n        if rank[ra] < rank[rb]:\n            parent[ra] = rb\n        elif rank[ra] > rank[rb]:\n            parent[rb] = ra\n        else:\n            parent[rb] = ra\n            rank[ra] += 1\n    for u, v in edges:\n        union(u, v)\n    return len({find(i) for i in range(n)})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enumerate All Cycles in Directed Graphs\nTarjan-style DFS that collects simple cycles without stopping at first detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import defaultdict\n\ndef all_cycles_directed(graph):\n    path, blocked = [], set()\n    result = []\n    graph = {k: set(v) for k, v in graph.items()}\n    def dfs(v, start):\n        path.append(v)\n        blocked.add(v)\n        for w in graph.get(v, []):\n            if w == start:\n                result.append(path.copy())\n            elif w not in blocked:\n                dfs(w, start)\n        path.pop()\n        blocked.discard(v)\n    for node in graph:\n        dfs(node, node)\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time-Dependent Grid Shortest Path\nExpands BFS state with timestamp to respect obstacle schedules (time dimension in visited key)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import deque\n\ndef shortest_time_path(grid, is_blocked_at):\n    rows, cols = len(grid), len(grid[0])\n    start, target = (0, 0), (rows - 1, cols - 1)\n    q = deque([(start[0], start[1], 0)])\n    seen = {(start[0], start[1], 0)}\n    while q:\n        r, c, t = q.popleft()\n        if (r, c) == target:\n            return t\n        for dr, dc in [(1,0),(-1,0),(0,1),(0,-1)]:\n            nr, nc = r + dr, c + dc\n            nt = t + 1\n            if 0 <= nr < rows and 0 <= nc < cols and not is_blocked_at(nr, nc, nt):\n                state = (nr, nc, nt)\n                if state not in seen:\n                    seen.add(state)\n                    q.append((nr, nc, nt))\n    return -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Word Break with Minimal Segmentation (Trie + DP)\nBuilds a trie for O(n\u00b7\u03a3) traversal and reconstructs the fewest-word split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class TrieNode:\n    __slots__ = (\"children\", \"end\")\n    def __init__(self):\n        self.children = {}\n        self.end = False\n\ndef word_break_min(words, s):\n    root = TrieNode()\n    for w in words:\n        node = root\n        for ch in w:\n            node = node.children.setdefault(ch, TrieNode())\n        node.end = True\n    n = len(s)\n    dp = [None] * (n + 1)\n    dp[0] = []\n    for i in range(n):\n        if dp[i] is None:\n            continue\n        node = root\n        for j in range(i, n):\n            ch = s[j]\n            if ch not in node.children:\n                break\n            node = node.children[ch]\n            if node.end:\n                if dp[j+1] is None or len(dp[i]) + 1 < len(dp[j+1]):\n                    dp[j+1] = dp[i] + [s[i:j+1]]\n    return dp[n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Streaming Knapsack (Incremental Recompute)\nMaintains DP table that can be updated as items stream in without restarting from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def streaming_knapsack(stream, capacity):\n    dp = [0] * (capacity + 1)\n    for value, weight in stream:\n        for w in range(capacity, weight - 1, -1):\n            dp[w] = max(dp[w], dp[w - weight] + value)\n        yield max(dp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom-Cost Optimal Parenthesization\nDynamic programming over interval splits parameterized by user-supplied cost matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def optimal_parenthesization(costs):\n    n = len(costs)\n    dp = [[0] * n for _ in range(n)]\n    split = [[-1] * n for _ in range(n)]\n    for length in range(2, n + 1):\n        for i in range(n - length + 1):\n            j = i + length - 1\n            best = float('inf')\n            for k in range(i, j):\n                cand = dp[i][k] + dp[k+1][j] + costs[i][k] + costs[k+1][j]\n                if cand < best:\n                    best = cand\n                    split[i][j] = k\n            dp[i][j] = best\n    return dp[0][n-1], split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Serialize Trees with Possible Cycles\nAssigns IDs and records adjacency so corrupted pointers or cycles remain representable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import json\n\ndef serialize_tree(root):\n    node_ids = {}\n    edges = []\n    def walk(node):\n        if node in node_ids:\n            return node_ids[node]\n        idx = len(node_ids)\n        node_ids[node] = idx\n        left = walk(node.left) if getattr(node, 'left', None) else None\n        right = walk(node.right) if getattr(node, 'right', None) else None\n        edges.append({\"id\": idx, \"val\": node.val, \"left\": left, \"right\": right})\n        return idx\n    walk(root)\n    return json.dumps({\"nodes\": edges})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LCA in Huge Non-Binary Trees\nParent pointers let us climb ancestors with a visited set using only O(h) memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def lca_with_parents(parent_map, a, b):\n    seen = set()\n    while a is not None:\n        seen.add(a)\n        a = parent_map.get(a)\n    while b is not None:\n        if b in seen:\n            return b\n        b = parent_map.get(b)\n    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Versioned Trie with Wildcards and Rollback\nStores snapshots via persistent nodes to support deletion, wildcard search, and version history."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class VersionedTrieNode:\n    __slots__ = (\"children\", \"end\")\n    def __init__(self, children=None, end=False):\n        self.children = children or {}\n        self.end = end\n\ndef trie_insert(root, word):\n    node = VersionedTrieNode(dict(root.children), root.end)\n    cur = node\n    for ch in word:\n        cur.children[ch] = VersionedTrieNode(dict(cur.children.get(ch, VersionedTrieNode()).children), cur.children.get(ch, VersionedTrieNode()).end)\n        cur = cur.children[ch]\n    cur.end = True\n    return node\n\ndef trie_search(root, pattern):\n    def dfs(node, idx):\n        if idx == len(pattern):\n            return node.end\n        ch = pattern[idx]\n        if ch == '*':\n            return any(dfs(child, idx + 1) for child in node.children.values())\n        if ch in node.children:\n            return dfs(node.children[ch], idx + 1)\n        return False\n    return dfs(root, 0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## O(1) LRU with TTL and Priority Updates\nDoubly linked list for recency plus min-heap keyed by expiry; priority updates adjust positions in O(1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import time\nclass LRUNode:\n    __slots__ = (\"key\",\"value\",\"prev\",\"next\",\"expires_at\")\n    def __init__(self, key, value, ttl):\n        self.key, self.value = key, value\n        self.prev = self.next = None\n        self.expires_at = time.time() + ttl\n\nclass LRUCache:\n    def __init__(self, capacity):\n        self.cap = capacity\n        self.map = {}\n        self.head = LRUNode(None, None, 0)\n        self.tail = LRUNode(None, None, 0)\n        self.head.next = self.tail\n        self.tail.prev = self.head\n    def _add_front(self, node):\n        node.next = self.head.next\n        node.prev = self.head\n        self.head.next.prev = node\n        self.head.next = node\n    def _remove(self, node):\n        node.prev.next = node.next\n        node.next.prev = node.prev\n    def get(self, key):\n        node = self.map.get(key)\n        if not node or node.expires_at < time.time():\n            return None\n        self._remove(node)\n        self._add_front(node)\n        return node.value\n    def put(self, key, value, ttl=60):\n        if key in self.map:\n            self._remove(self.map[key])\n        node = LRUNode(key, value, ttl)\n        self.map[key] = node\n        self._add_front(node)\n        if len(self.map) > self.cap:\n            lru = self.tail.prev\n            self._remove(lru)\n            del self.map[lru.key]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Thread-Safe Lock-Free Queue (ABA-Safe Sketch)\nUses CAS-like semantics and version tags to avoid ABA; Python mock-up with locks standing in for atomic ops for illustration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import threading\n\nclass LockFreeNode:\n    __slots__ = (\"value\",\"next\",\"tag\")\n    def __init__(self, value=None, nxt=None, tag=0):\n        self.value, self.next, self.tag = value, nxt, tag\n\nclass LockFreeQueue:\n    def __init__(self):\n        node = LockFreeNode()\n        self.head = self.tail = node\n        self.lock = threading.Lock()\n    def enqueue(self, value):\n        with self.lock:\n            node = LockFreeNode(value)\n            self.tail.next = node\n            self.tail.tag += 1\n            self.tail = node\n    def dequeue(self):\n        with self.lock:\n            if not self.head.next:\n                return None\n            node = self.head.next\n            self.head = node\n            return node.value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mergeable Bloom Filter\nCombines bit arrays with multiple hash functions; merge uses bitwise OR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import mmh3\nclass Bloom:\n    def __init__(self, m, k, seed=0):\n        self.bits = 0\n        self.m, self.k, self.seed = m, k, seed\n    def _hashes(self, item):\n        for i in range(self.k):\n            yield mmh3.hash(str(item), self.seed + i) % self.m\n    def add(self, item):\n        for h in self._hashes(item):\n            self.bits |= 1 << h\n    def contains(self, item):\n        return all((self.bits >> h) & 1 for h in self._hashes(item))\n    def merge(self, other):\n        assert (self.m, self.k) == (other.m, other.k)\n        merged = Bloom(self.m, self.k, self.seed)\n        merged.bits = self.bits | other.bits\n        return merged\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Singleton without Double-Checked Locking Pitfalls\nLeverages module-level variable plus threading.Lock to ensure safe lazy instantiation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import threading\n\nclass Singleton:\n    _instance = None\n    _lock = threading.Lock()\n\n    @classmethod\n    def instance(cls):\n        if cls._instance is None:\n            with cls._lock:\n                if cls._instance is None:\n                    cls._instance = cls()\n        return cls._instance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fair Reader-Writer Lock\nTwo-condition-variable implementation that prevents starvation by honoring arrival order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "class FairRWLock:\n    def __init__(self):\n        self.readers = 0\n        self.writer = False\n        self.cv = threading.Condition()\n    def acquire_read(self):\n        with self.cv:\n            while self.writer:\n                self.cv.wait()\n            self.readers += 1\n    def release_read(self):\n        with self.cv:\n            self.readers -= 1\n            if self.readers == 0:\n                self.cv.notify_all()\n    def acquire_write(self):\n        with self.cv:\n            while self.writer or self.readers > 0:\n                self.cv.wait()\n            self.writer = True\n    def release_write(self):\n        with self.cv:\n            self.writer = False\n            self.cv.notify_all()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prioritized Worker Pool with Metrics\nSupports dynamic resizing and task priority via heap; tracks completions and failures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import time, heapq\nfrom threading import Thread, Event, Lock\n\nclass WorkerPool:\n    def __init__(self, size=4):\n        self.size = size\n        self.tasks = []\n        self.cv = threading.Condition()\n        self.stop = Event()\n        self.threads = []\n        self.metrics = {\"done\":0,\"failed\":0}\n        self._spawn()\n    def _spawn(self):\n        for _ in range(self.size):\n            t = Thread(target=self._run, daemon=True)\n            t.start()\n            self.threads.append(t)\n    def submit(self, priority, fn, *args, **kwargs):\n        with self.cv:\n            heapq.heappush(self.tasks, (priority, time.time(), fn, args, kwargs))\n            self.cv.notify()\n    def resize(self, new_size):\n        if new_size > self.size:\n            self.size = new_size\n            self._spawn()\n        else:\n            self.size = new_size\n    def _run(self):\n        while not self.stop.is_set():\n            with self.cv:\n                while not self.tasks and not self.stop.is_set():\n                    self.cv.wait()\n                if self.stop.is_set():\n                    break\n                priority, _, fn, args, kwargs = heapq.heappop(self.tasks)\n            try:\n                fn(*args, **kwargs)\n                self.metrics[\"done\"] += 1\n            except Exception:\n                self.metrics[\"failed\"] += 1\n    def shutdown(self):\n        self.stop.set()\n        with self.cv:\n            self.cv.notify_all()\n        for t in self.threads:\n            t.join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dining Philosophers without Starvation\nUse resource hierarchy (ordered forks) to avoid deadlocks and round-robin start delays to reduce starvation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def dining_philosophers(forks, iterations=1):\n    n = len(forks)\n    def philosopher(i):\n        left, right = min(i, (i+1)%n), max(i, (i+1)%n)\n        for _ in range(iterations):\n            with forks[left]:\n                with forks[right]:\n                    pass\n    threads = [threading.Thread(target=philosopher, args=(i,)) for i in range(n)]\n    for t in threads: t.start()\n    for t in threads: t.join()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Consistent Hashing with Virtual Nodes\nDistributes keys across replicas evenly; add/remove nodes by adjusting ring entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import bisect, hashlib\nclass ConsistentHash:\n    def __init__(self, replicas=100):\n        self.replicas = replicas\n        self.ring = []\n        self.nodes = {}\n    def _hash(self, key):\n        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n    def add_node(self, node):\n        for i in range(self.replicas):\n            h = self._hash(f\"{node}:{i}\")\n            self.nodes[h] = node\n            bisect.insort(self.ring, h)\n    def remove_node(self, node):\n        for i in range(self.replicas):\n            h = self._hash(f\"{node}:{i}\")\n            if h in self.nodes:\n                del self.nodes[h]\n                self.ring.remove(h)\n    def get(self, key):\n        if not self.ring:\n            return None\n        h = self._hash(key)\n        idx = bisect.bisect(self.ring, h) % len(self.ring)\n        return self.nodes[self.ring[idx]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Clocks for Conflict Resolution\nCompares version maps to classify causality relationships."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def compare_vc(a, b):\n    keys = set(a) | set(b)\n    less = greater = False\n    for k in keys:\n        av, bv = a.get(k, 0), b.get(k, 0)\n        if av < bv:\n            less = True\n        elif av > bv:\n            greater = True\n    if less and greater:\n        return \"concurrent\"\n    if less:\n        return \"before\"\n    if greater:\n        return \"after\"\n    return \"equal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mini MapReduce for Word Count\nCoordinator assigns shards, workers emit local counts, reducer aggregates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from collections import Counter\n\ndef map_reduce_word_count(chunks):\n    mapped = [Counter(chunk.split()) for chunk in chunks]\n    total = Counter()\n    for partial in mapped:\n        total.update(partial)\n    return total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Structure & Complexity Primer\n",
        "Brief refreshers for each classic problem: what the structure is, how it is traversed, and how to reason about time/space using dominant operations (visiting nodes, heap pushes, hash lookups). For asymptotic cost, count the highest-order terms of the critical loops or recursive calls; ignore constants and lower-order terms to derive Big-O."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Two Sum (hash map)\n",
        "Store seen values in a hash map keyed by number with index as value; for each new number, check if target-num exists. Traversal is linear; hash lookups are O(1) average.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\nfrom typing import List, Tuple\ndef two_sum(nums: List[int], target: int) -> Tuple[int,int] | None:\n    seen={}\n    for i,n in enumerate(nums):\n        if (target-n) in seen:\n            return seen[target-n], i\n        seen[n]=i\n    return None\n# Time: O(n), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate Subsequence\n",
        "Walk through array once, advancing a pointer on subsequence matches; single pass traversal of n elements.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef is_valid_subsequence(array, sequence):\n    j=0\n    for x in array:\n        if j < len(sequence) and sequence[j]==x:\n            j+=1\n    return j==len(sequence)\n# Time: O(n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sorted Squared Array\n",
        "Map to squares then sort, or use two-pointer merge from ends for linear time on already sorted input.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef sorted_squared_array(arr: List[int]) -> List[int]:\n    res=[0]*len(arr)\n    l,r=0,len(arr)-1\n    for i in range(len(arr)-1,-1,-1):\n        if abs(arr[l])>abs(arr[r]):\n            res[i]=arr[l]*arr[l]; l+=1\n        else:\n            res[i]=arr[r]*arr[r]; r-=1\n    return res\n# Time: O(n), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Non-Constructible Change\n",
        "Sort coins and keep a running constructible range; if next coin exceeds range+1, gap found.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef non_constructible_change(coins: List[int]) -> int:\n    coins.sort()\n    current=0\n    for c in coins:\n        if c>current+1:\n            return current+1\n        current+=c\n    return current+1\n# Time: O(n log n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tournament Winner\n",
        "Track team scores in a hash map as matches are traversed; compute max at end.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef tournament_winner(competitions, results):\n    scores={}\n    best=(None,0)\n    for (home,away),res in zip(competitions, results):\n        winner=home if res==1 else away\n        scores[winner]=scores.get(winner,0)+3\n        if scores[winner]>best[1]:\n            best=(winner,scores[winner])\n    return best[0]\n# Time: O(n), Space: O(t)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Caesar Cipher\n",
        "Shift letters modulo alphabet; traverse characters once.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef caesar_cipher(text: str, k: int) -> str:\n    k%=26\n    res=[]\n    for ch in text:\n        if 'a'<=ch<='z':\n            res.append(chr((ord(ch)-97+k)%26+97))\n        elif 'A'<=ch<='Z':\n            res.append(chr((ord(ch)-65+k)%26+65))\n        else:\n            res.append(ch)\n    return ''.join(res)\n# Time: O(n), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run-Length Encoding\n",
        "Traverse string and compress consecutive runs; linear scan and append counts.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef run_length_encode(s: str) -> str:\n    out=[]; count=1\n    for i in range(1,len(s)+1):\n        if i<len(s) and s[i]==s[i-1] and count<9:\n            count+=1\n        else:\n            out.append(f\"{count}{s[i-1]}\"); count=1\n    return ''.join(out)\n# Time: O(n), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Palindrome Check\n",
        "Compare characters from both ends moving inward; stops when pointers cross.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef is_palindrome(s: str) -> bool:\n    l,r=0,len(s)-1\n    while l<r:\n        if s[l]!=s[r]:\n            return False\n        l+=1; r-=1\n    return True\n# Time: O(n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nth Fibonacci (iterative)\n",
        "Iterative accumulation with two pointers avoids recursion stack.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef nth_fib(n: int) -> int:\n    if n<=1: return n\n    a,b=0,1\n    for _ in range(2,n+1):\n        a,b=b,a+b\n    return b\n# Time: O(n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Product Sum (nested lists)\n",
        "Depth-first traversal multiplies sums by depth; recursion visits each element once.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef product_sum(array, depth=1):\n    total=0\n    for el in array:\n        if isinstance(el, list):\n            total+=product_sum(el, depth+1)\n        else:\n            total+=el\n    return total*depth\n# Time: O(n), Space: O(d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Binary Search\n",
        "Repeatedly halve search interval in a sorted array using mid index checks.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef binary_search(arr: List[int], target: int) -> int:\n    l,r=0,len(arr)-1\n    while l<=r:\n        m=(l+r)//2\n        if arr[m]==target: return m\n        if arr[m]<target: l=m+1\n        else: r=m-1\n    return -1\n# Time: O(log n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find Three Largest Numbers\n",
        "Single pass maintaining three rolling maxima.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef three_largest(nums: List[int]) -> List[int]:\n    top=[float('-inf')]*3\n    for n in nums:\n        if n>=top[2]:\n            top=[top[1], top[2], n]\n        elif n>=top[1]:\n            top=[top[1], n, top[2]]\n        elif n>=top[0]:\n            top=[n, top[1], top[2]]\n    return top\n# Time: O(n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bubble / Insertion / Selection Sort\n",
        "Classic quadratic traversals comparing adjacent or scanning remainder; show mechanics and costs.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef bubble_sort(arr: List[int]) -> List[int]:\n    a=arr[:]\n    for i in range(len(a)):\n        for j in range(0,len(a)-i-1):\n            if a[j]>a[j+1]:\n                a[j],a[j+1]=a[j+1],a[j]\n    return a\ndef insertion_sort(arr: List[int]) -> List[int]:\n    a=arr[:]\n    for i in range(1,len(a)):\n        j=i\n        while j>0 and a[j]<a[j-1]:\n            a[j],a[j-1]=a[j-1],a[j]; j-=1\n    return a\ndef selection_sort(arr: List[int]) -> List[int]:\n    a=arr[:]\n    for i in range(len(a)):\n        m=i\n        for j in range(i+1,len(a)):\n            if a[j]<a[m]: m=j\n        a[i],a[m]=a[m],a[i]\n    return a\n# Time: O(n^2), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Move Element to End\n",
        "Two-pointer sweep swapping target values to the back.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef move_to_end(arr: List[int], target: int) -> List[int]:\n    l,r=0,len(arr)-1\n    while l<r:\n        while l<r and arr[r]==target:\n            r-=1\n        if arr[l]==target:\n            arr[l],arr[r]=arr[r],arr[l]\n        l+=1\n    return arr\n# Time: O(n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monotonic Array\n",
        "Check direction once and ensure no violations.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef is_monotonic(arr: List[int]) -> bool:\n    inc=dec=True\n    for i in range(1,len(arr)):\n        inc &= arr[i]>=arr[i-1]\n        dec &= arr[i]<=arr[i-1]\n    return inc or dec\n# Time: O(n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Spiral Traverse\n",
        "Layer-by-layer traversal updating bounds until all elements visited.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef spiral_traverse(matrix: List[List[int]]) -> List[int]:\n    res=[]; top=0; bottom=len(matrix)-1; left=0; right=len(matrix[0])-1\n    while top<=bottom and left<=right:\n        for c in range(left,right+1): res.append(matrix[top][c])\n        for r in range(top+1,bottom+1): res.append(matrix[r][right])\n        if top<bottom:\n            for c in range(right-1,left-1,-1): res.append(matrix[bottom][c])\n        if left<right:\n            for r in range(bottom-1,top,-1): res.append(matrix[r][left])\n        top+=1; bottom-=1; left+=1; right-=1\n    return res\n# Time: O(n), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Longest Peak\n",
        "Identify peaks where neighbors are smaller, then expand outward counting length.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef longest_peak(arr: List[int]) -> int:\n    longest=0; i=1\n    while i<len(arr)-1:\n        if arr[i-1]<arr[i]>arr[i+1]:\n            l=i-2; r=i+2; length=3\n            while l>=0 and arr[l]<arr[l+1]:\n                length+=1; l-=1\n            while r<len(arr) and arr[r]<arr[r-1]:\n                length+=1; r+=1\n            longest=max(longest,length); i=r\n        else:\n            i+=1\n    return longest\n# Time: O(n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Array of Products\n",
        "Prefix and suffix products computed in two linear passes.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef array_of_products(arr: List[int]) -> List[int]:\n    n=len(arr); res=[1]*n\n    prefix=1\n    for i in range(n):\n        res[i]=prefix; prefix*=arr[i]\n    suffix=1\n    for i in range(n-1,-1,-1):\n        res[i]*=suffix; suffix*=arr[i]\n    return res\n# Time: O(n), Space: O(1) extra\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Minimum Rewards\n",
        "Sort by scores implicitly using left/right passes counting increasing streaks.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef min_rewards(scores: List[int]) -> int:\n    n=len(scores); rewards=[1]*n\n    for i in range(1,n):\n        if scores[i]>scores[i-1]:\n            rewards[i]=rewards[i-1]+1\n    for i in range(n-2,-1,-1):\n        if scores[i]>scores[i+1]:\n            rewards[i]=max(rewards[i], rewards[i+1]+1)\n    return sum(rewards)\n# Time: O(n), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## River Sizes (graph DFS)\n",
        "Traverse the grid; DFS each unvisited land cell counting connected area.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef river_sizes(matrix: List[List[int]]) -> List[int]:\n    if not matrix: return []\n    visited=[[False]*len(matrix[0]) for _ in matrix]\n    res=[]\n    def dfs(r,c):\n        stack=[(r,c)]; size=0\n        while stack:\n            x,y=stack.pop()\n            if visited[x][y]: continue\n            visited[x][y]=True\n            if matrix[x][y]==0: continue\n            size+=1\n            for dx,dy in ((1,0),(-1,0),(0,1),(0,-1)):\n                nx,ny=x+dx,y+dy\n                if 0<=nx<len(matrix) and 0<=ny<len(matrix[0]) and not visited[nx][ny]:\n                    stack.append((nx,ny))\n        return size\n    for i in range(len(matrix)):\n        for j in range(len(matrix[0])):\n            if not visited[i][j] and matrix[i][j]==1:\n                res.append(dfs(i,j))\n    return res\n# Time: O(rc), Space: O(rc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Binary Trees: BFS/DFS\n",
        "Level-order uses a queue; DFS uses recursion/stack. Each visits every node once.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\nclass BTNode:\n    def __init__(self,val,left=None,right=None):\n        self.val=val; self.left=left; self.right=right\ndef bfs(root: BTNode) -> list[int]:\n    if not root: return []\n    q=[root]; out=[]\n    while q:\n        node=q.pop(0); out.append(node.val)\n        if node.left: q.append(node.left)\n        if node.right: q.append(node.right)\n    return out\ndef dfs_preorder(root: BTNode) -> list[int]:\n    res=[]\n    def helper(node):\n        if not node: return\n        res.append(node.val)\n        helper(node.left); helper(node.right)\n    helper(root); return res\n# Time: O(n), Space: O(n) worst-case\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BST Closest Value\n",
        "Walk down the BST comparing distances; branch left/right by BST property.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\nclass BST:\n    def __init__(self, val):\n        self.value=val; self.left=None; self.right=None\ndef find_closest_value(tree: BST, target: int) -> int:\n    closest=tree.value\n    node=tree\n    while node:\n        if abs(target-node.value)<abs(target-closest):\n            closest=node.value\n        node=node.left if target<node.value else node.right\n    return closest\n# Time: O(h), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Branch Sums & Node Depths\n",
        "Recursive traversal accumulating path sums or depth counts.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef branch_sums(root: BTNode) -> list[int]:\n    res=[]\n    def helper(node, running):\n        if not node: return\n        running+=node.val\n        if not node.left and not node.right:\n            res.append(running); return\n        helper(node.left, running); helper(node.right, running)\n    helper(root,0); return res\ndef node_depths(root: BTNode, depth=0) -> int:\n    if not root: return 0\n    return depth + node_depths(root.left, depth+1) + node_depths(root.right, depth+1)\n# Time: O(n), Space: O(h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Invert Binary Tree\n",
        "Swap children recursively or iteratively; mirrors the tree.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef invert_tree(root: BTNode) -> BTNode:\n    if not root: return root\n    root.left, root.right = invert_tree(root.right), invert_tree(root.left)\n    return root\n# Time: O(n), Space: O(h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Min Height BST\n",
        "Insert midpoints of sorted array to keep tree balanced via recursion.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef min_height_bst(sorted_array: List[int]) -> BST:\n    def build(lo,hi):\n        if lo>hi: return None\n        mid=(lo+hi)//2\n        node=BST(sorted_array[mid])\n        node.left=build(lo, mid-1)\n        node.right=build(mid+1, hi)\n        return node\n    return build(0, len(sorted_array)-1)\n# Time: O(n), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Max Subset Sum No Adjacent\n",
        "DP over array choosing max of take vs skip using rolling variables.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef max_subset_no_adjacent(arr: List[int]) -> int:\n    if not arr: return 0\n    if len(arr)==1: return arr[0]\n    incl=arr[0]; excl=max(arr[0], arr[1])\n    for n in arr[2:]:\n        incl,excl=excl, max(excl, incl+n)\n    return excl\n# Time: O(n), Space: O(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Number of Ways to Make Change\n",
        "DP accumulating combinations for each coin and amount.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef ways_to_make_change(n: int, coins: List[int]) -> int:\n    ways=[0]*(n+1)\n    ways[0]=1\n    for coin in coins:\n        for amt in range(coin, n+1):\n            ways[amt]+=ways[amt-coin]\n    return ways[n]\n# Time: O(n * c), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Levenshtein Distance\n",
        "Classic DP grid comparing prefixes; fill row by row using edit costs.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef levenshtein(a: str, b: str) -> int:\n    if len(a)<len(b): a,b=b,a\n    prev=list(range(len(b)+1))\n    for i,ca in enumerate(a,1):\n        cur=[i]\n        for j,cb in enumerate(b,1):\n            if ca==cb:\n                cur.append(prev[j-1])\n            else:\n                cur.append(1+min(prev[j-1], prev[j], cur[-1]))\n        prev=cur\n    return prev[-1]\n# Time: O(len(a)*len(b)), Space: O(min(len(a),len(b)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Permutations & Powerset\n",
        "Backtracking traverses decision tree; branching yields exponential outputs.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef permutations(arr: List[int]) -> List[List[int]]:\n    res=[]\n    def backtrack(path, used):\n        if len(path)==len(arr):\n            res.append(path[:]); return\n        for i,n in enumerate(arr):\n            if used[i]: continue\n            used[i]=True; path.append(n)\n            backtrack(path, used)\n            path.pop(); used[i]=False\n    backtrack([], [False]*len(arr)); return res\ndef powerset(arr: List[int]) -> List[List[int]]:\n    res=[[]]\n    for n in arr:\n        res += [subset+[n] for subset in res]\n    return res\n# Time: O(n*n!), O(n*2^n); Space proportional to outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Balanced Brackets\n",
        "Push opening brackets onto stack; pop and validate matching closes.",
        "\n\n**Big-O:** see code cell comment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\ndef balanced_brackets(s: str) -> bool:\n    pairs={')':'(',']':'[','}':'{'}; stack=[]\n    for ch in s:\n        if ch in '([{': stack.append(ch)\n        elif ch in pairs:\n            if not stack or stack.pop()!=pairs[ch]:\n                return False\n    return not stack\n# Time: O(n), Space: O(n)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comprehensive Solution Catalog\n",
        "\n",
        "Below are Python reference implementations for the **Easy** practice set requested. Each function is self-contained and includes inline Big-O notes. Medium and harder variants follow the same patterns documented earlier in the notebook (two-pointer arrays, heaps for k-way merges, DFS/BFS over graphs/trees, dynamic programming for subsequences, greedy for scheduling, and heap/union-find for graph spanning problems). Use these foundations to extend into the Medium/Hard/Very Hard lists.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": [
        "\"\"\"Easy practice set implementations with inline Big-O notes.\"\"\"",
        "from collections import Counter, deque",
        "",
        "def validate_subsequence(array, sequence):",
        "    it = iter(array)",
        "    return all(val in it for val in sequence)  # O(n) time, O(1) space",
        "",
        "def two_number_sum(array, target):",
        "    seen = set()",
        "    for x in array:",
        "        if target - x in seen:",
        "            return [target - x, x]",
        "        seen.add(x)",
        "    return []  # O(n) time, O(n) space",
        "",
        "def sorted_squared_array(arr):",
        "    res=[0]*len(arr)",
        "    l,r=0,len(arr)-1",
        "    for i in range(len(arr)-1,-1,-1):",
        "        if abs(arr[l])>abs(arr[r]):",
        "            res[i]=arr[l]**2;l+=1",
        "        else:",
        "            res[i]=arr[r]**2;r-=1",
        "    return res  # O(n) time, O(n) space",
        "",
        "def tournament_winner(competitions, results):",
        "    scores=Counter(); best=''",
        "    for (home,away),res in zip(competitions,results):",
        "        winner=home if res==1 else away",
        "        scores[winner]+=3",
        "        if scores[winner]>scores[best]:",
        "            best=winner",
        "    return best  # O(m) time",
        "",
        "def non_constructible_change(coins):",
        "    coins.sort(); change=0",
        "    for coin in coins:",
        "        if coin>change+1:",
        "            return change+1",
        "        change+=coin",
        "    return change+1  # O(n log n)",
        "",
        "def transpose_matrix(matrix):",
        "    return [list(row) for row in zip(*matrix)]  # O(r*c)",
        "",
        "def find_closest_value_in_bst(tree, target):",
        "    node=tree; closest=tree.value",
        "    while node:",
        "        if abs(target-node.value)<abs(target-closest):",
        "            closest=node.value",
        "        node=node.left if target<node.value else node.right",
        "    return closest  # O(h)",
        "",
        "def branch_sums(root):",
        "    sums=[]",
        "    def dfs(node,total):",
        "        if not node:",
        "            return",
        "        total+=node.value",
        "        if not node.left and not node.right:",
        "            sums.append(total); return",
        "        dfs(node.left,total); dfs(node.right,total)",
        "    dfs(root,0); return sums  # O(n)",
        "",
        "def node_depths(root):",
        "    total=0; stack=[(root,0)]",
        "    while stack:",
        "        node,depth=stack.pop()",
        "        if not node: continue",
        "        total+=depth",
        "        stack.append((node.left,depth+1)); stack.append((node.right,depth+1))",
        "    return total  # O(n)",
        "",
        "def evaluate_expression_tree(tree):",
        "    if not tree.left and not tree.right:",
        "        return tree.value",
        "    left=evaluate_expression_tree(tree.left)",
        "    right=evaluate_expression_tree(tree.right)",
        "    if tree.value== -1: return left+right",
        "    if tree.value== -2: return left-right",
        "    if tree.value== -3: return left//right",
        "    if tree.value== -4: return left*right",
        "    raise ValueError('Unknown op')  # O(n)",
        "",
        "def depth_first_search(node, array):",
        "    array.append(node.name)",
        "    for child in node.children:",
        "        depth_first_search(child,array)",
        "    return array  # O(v+e)",
        "",
        "def minimum_waiting_time(queries):",
        "    queries.sort(); total=0; prefix=0",
        "    for q in queries[:-1]:",
        "        prefix+=q; total+=prefix",
        "    return total  # O(n log n)",
        "",
        "def class_photos(red, blue):",
        "    red.sort(); blue.sort(); first_red=red[0]<blue[0]",
        "    for r,b in zip(red,blue):",
        "        if (r>=b and first_red) or (b>=r and not first_red):",
        "            return False",
        "    return True  # O(n log n)",
        "",
        "def tandem_bicycle(red, blue, fastest):",
        "    red.sort(); blue.sort(reverse=fastest)",
        "    return sum(max(r,b) for r,b in zip(red,blue))  # O(n log n)",
        "",
        "def optimal_freelancing(jobs):",
        "    pay=[0]*7",
        "    for job in jobs:",
        "        deadline=min(6,job['deadline']-1)",
        "        for d in range(deadline,-1,-1):",
        "            if pay[d]==0:",
        "                pay[d]=job['payment']; break",
        "    return sum(pay)  # O(7*j)",
        "",
        "def remove_duplicates_from_linked_list(head):",
        "    cur=head",
        "    while cur and cur.next:",
        "        if cur.value==cur.next.value:",
        "            cur.next=cur.next.next",
        "        else:",
        "            cur=cur.next",
        "    return head  # O(n)",
        "",
        "def middle_node(head):",
        "    slow=fast=head",
        "    while fast and fast.next:",
        "        slow=slow.next; fast=fast.next.next",
        "    return slow  # O(n)",
        "",
        "def nth_fibonacci(n):",
        "    a,b=0,1",
        "    for _ in range(n):",
        "        a,b=b,a+b",
        "    return a  # O(n)",
        "",
        "def product_sum(array, depth=1):",
        "    total=0",
        "    for item in array:",
        "        if isinstance(item,list):",
        "            total+=product_sum(item,depth+1)",
        "        else:",
        "            total+=item",
        "    return total*depth  # O(n)",
        "",
        "def binary_search(array, target):",
        "    l,r=0,len(array)-1",
        "    while l<=r:",
        "        m=(l+r)//2",
        "        if array[m]==target:",
        "            return m",
        "        if array[m]<target: l=m+1",
        "        else: r=m-1",
        "    return -1  # O(log n)",
        "",
        "def find_three_largest_numbers(array):",
        "    top=[float('-inf')]*3",
        "    for x in array:",
        "        if x>=top[2]: top=[top[1],top[2],x]",
        "        elif x>=top[1]: top=[top[1],x,top[2]]",
        "        elif x>=top[0]: top=[x,top[1],top[2]]",
        "    return top  # O(n)",
        "",
        "def bubble_sort(arr):",
        "    a=arr[:]",
        "    n=len(a)",
        "    for i in range(n):",
        "        for j in range(0,n-i-1):",
        "            if a[j]>a[j+1]:",
        "                a[j],a[j+1]=a[j+1],a[j]",
        "    return a  # O(n^2)",
        "",
        "def insertion_sort(arr):",
        "    a=arr[:]",
        "    for i in range(1,len(a)):",
        "        key=a[i]; j=i-1",
        "        while j>=0 and a[j]>key:",
        "            a[j+1]=a[j]; j-=1",
        "        a[j+1]=key",
        "    return a  # O(n^2)",
        "",
        "def selection_sort(arr):",
        "    a=arr[:]",
        "    for i in range(len(a)):",
        "        m=i",
        "        for j in range(i+1,len(a)):",
        "            if a[j]<a[m]: m=j",
        "        a[i],a[m]=a[m],a[i]",
        "    return a  # O(n^2)",
        "",
        "def palindrome_check(s):",
        "    return s==s[::-1]  # O(n)",
        "",
        "def caesar_cipher_encryptor(s,key):",
        "    key%=26",
        "    return ''.join(chr(((ord(c)-97+key)%26)+97) for c in s)  # O(n)",
        "",
        "def run_length_encoding(s):",
        "    res=[];count=1",
        "    for i in range(1,len(s)+1):",
        "        if i<len(s) and s[i]==s[i-1] and count<9:",
        "            count+=1",
        "        else:",
        "            res.append(f\"{count}{s[i-1]}\"); count=1",
        "    return ''.join(res)  # O(n)",
        "",
        "def common_characters(strings):",
        "    common=Counter(strings[0])",
        "    for s in strings[1:]:",
        "        common&=Counter(s)",
        "    return sorted(list(common.elements()))  # O(n*k)",
        "",
        "def generate_document(characters, document):",
        "    counts=Counter(characters)",
        "    for c in document:",
        "        counts[c]-=1",
        "        if counts[c]<0:",
        "            return False",
        "    return True  # O(n)",
        "",
        "def first_non_repeating_character(string):",
        "    counts=Counter(string)",
        "    for i,ch in enumerate(string):",
        "        if counts[ch]==1:",
        "            return i",
        "    return -1  # O(n)",
        "",
        "def semordnilap(words):",
        "    seen=set(); pairs=[]",
        "    for w in words:",
        "        r=w[::-1]",
        "        if r in seen:",
        "            pairs.append([w,r])",
        "        seen.add(w)",
        "    return pairs  # O(n*k)",
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}